apiVersion: v1
items:
- apiVersion: networking.k8s.io/v1
  kind: Ingress
  metadata:
    annotations:
      meta.helm.sh/release-name: unionai-controlplane
      meta.helm.sh/release-namespace: union-cp
      nginx.ingress.kubernetes.io/app-root: /v2
      nginx.ingress.kubernetes.io/force-ssl-redirect: "false"
      nginx.ingress.kubernetes.io/limit-rps: "100"
      nginx.ingress.kubernetes.io/proxy-body-size: 6m
      nginx.ingress.kubernetes.io/proxy-buffer-size: 32k
      nginx.ingress.kubernetes.io/proxy-buffers: 4 32k
      nginx.ingress.kubernetes.io/proxy-cookie-domain: ~^ .$host
      nginx.ingress.kubernetes.io/server-snippet: |
        client_header_timeout 604800;
        client_body_timeout 604800;
        # Increasing the default configuration from
        #        client_header_buffer_size       1k;
        #        large_client_header_buffers     4 8k;
        # to default of 16k and 32k for large buffer sizes. These sizes are chosen as a short term mediation until we can collect data to reason
        # about expected header sizs (PE-1101).
        # Historically, we have seen is with the previous 8k max buffer size , the auth endpoint of /me would throw 400 Bad request and due to this ingress controller
        # threw a 500 as it doesn't expect this status code on auth request expected range :  200 <= authcall.status(i.e status of /me call) <=300
        # Code link for ref : https://github.com/nginx/nginx/blob/e734df6664e70f118ca3140bcef6d4f1750fa8fa/src/http/modules/ngx_http_auth_request_module.c#L170-L179
        # Now the main reason we have seen 400 bad request is large size of the cookies which contribute to the header size.
        # We should keep reducing the size of what headers are being sent meanwhile we increase this size to mitigate the long header issue.
        client_header_buffer_size 16k;
        large_client_header_buffers 64 32k;
      nginx.ingress.kubernetes.io/service-upstream: "true"
    creationTimestamp: "2025-12-31T02:01:18Z"
    generation: 1
    labels:
      app.kubernetes.io/managed-by: Helm
    name: controlplane
    namespace: union-cp
    resourceVersion: "1767147225349343015"
    uid: 2d19fffd-9356-4aae-973c-3f85dcd39756
  spec:
    ingressClassName: controlplane
    rules:
    - http:
        paths:
        - backend:
            service:
              name: flyteadmin
              port:
                number: 87
          path: /openapi
          pathType: ImplementationSpecific
        - backend:
            service:
              name: flyteadmin
              port:
                number: 80
          path: /healthcheck
          pathType: ImplementationSpecific
        - backend:
            service:
              name: flyteadmin
              port:
                number: 80
          path: /me
          pathType: ImplementationSpecific
        - backend:
            service:
              name: flyteadmin
              port:
                number: 87
          path: /openapi/*
          pathType: ImplementationSpecific
        - backend:
            service:
              name: flyteadmin
              port:
                number: 80
          path: /.well-known
          pathType: ImplementationSpecific
        - backend:
            service:
              name: flyteadmin
              port:
                number: 80
          path: /.well-known/*
          pathType: ImplementationSpecific
        - backend:
            service:
              name: flyteadmin
              port:
                number: 80
          path: /login
          pathType: ImplementationSpecific
        - backend:
            service:
              name: flyteadmin
              port:
                number: 80
          path: /login/*
          pathType: ImplementationSpecific
        - backend:
            service:
              name: flyteadmin
              port:
                number: 80
          path: /logout
          pathType: ImplementationSpecific
        - backend:
            service:
              name: flyteadmin
              port:
                number: 80
          path: /logout/*
          pathType: ImplementationSpecific
        - backend:
            service:
              name: flyteadmin
              port:
                number: 80
          path: /callback
          pathType: ImplementationSpecific
        - backend:
            service:
              name: flyteadmin
              port:
                number: 80
          path: /callback/*
          pathType: ImplementationSpecific
        - backend:
            service:
              name: flyteadmin
              port:
                number: 80
          path: /config
          pathType: ImplementationSpecific
        - backend:
            service:
              name: flyteadmin
              port:
                number: 80
          path: /config/*
          pathType: ImplementationSpecific
        - backend:
            service:
              name: flyteadmin
              port:
                number: 80
          path: /oauth2
          pathType: ImplementationSpecific
        - backend:
            service:
              name: flyteadmin
              port:
                number: 80
          path: /oauth2/*
          pathType: ImplementationSpecific
        - backend:
            service:
              name: flyteadmin
              port:
                number: 80
          path: /auth
          pathType: ImplementationSpecific
        - backend:
            service:
              name: flyteadmin
              port:
                number: 80
          path: /auth/*
          pathType: ImplementationSpecific
        - backend:
            service:
              name: usage
              port:
                number: 81
          path: /enqueue_metronome_request/v1
          pathType: ImplementationSpecific
        - backend:
            service:
              name: usage
              port:
                number: 81
          path: /enqueue_metronome_request/v1/*
          pathType: ImplementationSpecific
        - backend:
            service:
              name: usage
              port:
                number: 81
          path: /enqueue_stripe_request/v1
          pathType: ImplementationSpecific
        - backend:
            service:
              name: usage
              port:
                number: 81
          path: /enqueue_stripe_request/v1/*
          pathType: ImplementationSpecific
    tls:
    - hosts:
      - localhost
      - controlplane-nginx-controller.union-cp.svc.cluster.local
      secretName: controlplane-tls-cert
  status:
    loadBalancer:
      ingress:
      - ip: 34.118.225.101
- apiVersion: networking.k8s.io/v1
  kind: Ingress
  metadata:
    annotations:
      meta.helm.sh/release-name: unionai-controlplane
      meta.helm.sh/release-namespace: union-cp
      nginx.ingress.kubernetes.io/app-root: /v2
      nginx.ingress.kubernetes.io/auth-cache-key: $http_flyte_authorization$http_cookie
      nginx.ingress.kubernetes.io/force-ssl-redirect: "false"
      nginx.ingress.kubernetes.io/limit-rps: "100"
      nginx.ingress.kubernetes.io/proxy-body-size: 6m
      nginx.ingress.kubernetes.io/proxy-buffer-size: 32k
      nginx.ingress.kubernetes.io/proxy-buffers: 4 32k
      nginx.ingress.kubernetes.io/proxy-cookie-domain: ~^ .$host
      nginx.ingress.kubernetes.io/server-snippet: |
        client_header_timeout 604800;
        client_body_timeout 604800;
        # Increasing the default configuration from
        #        client_header_buffer_size       1k;
        #        large_client_header_buffers     4 8k;
        # to default of 16k and 32k for large buffer sizes. These sizes are chosen as a short term mediation until we can collect data to reason
        # about expected header sizs (PE-1101).
        # Historically, we have seen is with the previous 8k max buffer size , the auth endpoint of /me would throw 400 Bad request and due to this ingress controller
        # threw a 500 as it doesn't expect this status code on auth request expected range :  200 <= authcall.status(i.e status of /me call) <=300
        # Code link for ref : https://github.com/nginx/nginx/blob/e734df6664e70f118ca3140bcef6d4f1750fa8fa/src/http/modules/ngx_http_auth_request_module.c#L170-L179
        # Now the main reason we have seen 400 bad request is large size of the cookies which contribute to the header size.
        # We should keep reducing the size of what headers are being sent meanwhile we increase this size to mitigate the long header issue.
        client_header_buffer_size 16k;
        large_client_header_buffers 64 32k;
      nginx.ingress.kubernetes.io/service-upstream: "true"
      nginx.org/websocket-services: dataproxy-service
    creationTimestamp: "2025-12-31T02:01:18Z"
    generation: 1
    labels:
      app.kubernetes.io/managed-by: Helm
    name: controlplane-console-protected
    namespace: union-cp
    resourceVersion: "1767147225552191021"
    uid: d0575e10-379c-42b0-9ef2-9a479d053ea4
  spec:
    ingressClassName: controlplane
    rules:
    - http:
        paths:
        - backend:
            service:
              name: flyteconsole
              port:
                number: 80
          path: /
          pathType: ImplementationSpecific
        - backend:
            service:
              name: flyteconsole
              port:
                number: 80
          path: /console
          pathType: ImplementationSpecific
        - backend:
            service:
              name: flyteconsole
              port:
                number: 80
          path: /console/*
          pathType: ImplementationSpecific
        - backend:
            service:
              name: flyteconsole
              port:
                number: 80
          path: /dashboard
          pathType: ImplementationSpecific
        - backend:
            service:
              name: flyteconsole
              port:
                number: 80
          path: /dashboard/*
          pathType: ImplementationSpecific
        - backend:
            service:
              name: flyteconsole
              port:
                number: 80
          path: /resources
          pathType: ImplementationSpecific
        - backend:
            service:
              name: flyteconsole
              port:
                number: 80
          path: /resources/*
          pathType: ImplementationSpecific
        - backend:
            service:
              name: flyteconsole
              port:
                number: 80
          path: /cost
          pathType: ImplementationSpecific
        - backend:
            service:
              name: flyteconsole
              port:
                number: 80
          path: /cost/*
          pathType: ImplementationSpecific
        - backend:
            service:
              name: flyteconsole
              port:
                number: 80
          path: /loading
          pathType: ImplementationSpecific
        - backend:
            service:
              name: flyteconsole
              port:
                number: 80
          path: /loading/*
          pathType: ImplementationSpecific
        - backend:
            service:
              name: unionconsole
              port:
                number: 80
          path: /v2
          pathType: ImplementationSpecific
        - backend:
            service:
              name: unionconsole
              port:
                number: 80
          path: /v2/*
          pathType: ImplementationSpecific
    tls:
    - hosts:
      - localhost
      - controlplane-nginx-controller.union-cp.svc.cluster.local
      secretName: controlplane-tls-cert
  status:
    loadBalancer:
      ingress:
      - ip: 34.118.225.101
- apiVersion: networking.k8s.io/v1
  kind: Ingress
  metadata:
    annotations:
      meta.helm.sh/release-name: unionai-controlplane
      meta.helm.sh/release-namespace: union-cp
      nginx.ingress.kubernetes.io/app-root: /v2
      nginx.ingress.kubernetes.io/force-ssl-redirect: "false"
      nginx.ingress.kubernetes.io/limit-rps: "100"
      nginx.ingress.kubernetes.io/proxy-body-size: 6m
      nginx.ingress.kubernetes.io/proxy-buffer-size: 32k
      nginx.ingress.kubernetes.io/proxy-buffers: 4 32k
      nginx.ingress.kubernetes.io/proxy-cookie-domain: ~^ .$host
      nginx.ingress.kubernetes.io/server-snippet: |
        client_header_timeout 604800;
        client_body_timeout 604800;
        # Increasing the default configuration from
        #        client_header_buffer_size       1k;
        #        large_client_header_buffers     4 8k;
        # to default of 16k and 32k for large buffer sizes. These sizes are chosen as a short term mediation until we can collect data to reason
        # about expected header sizs (PE-1101).
        # Historically, we have seen is with the previous 8k max buffer size , the auth endpoint of /me would throw 400 Bad request and due to this ingress controller
        # threw a 500 as it doesn't expect this status code on auth request expected range :  200 <= authcall.status(i.e status of /me call) <=300
        # Code link for ref : https://github.com/nginx/nginx/blob/e734df6664e70f118ca3140bcef6d4f1750fa8fa/src/http/modules/ngx_http_auth_request_module.c#L170-L179
        # Now the main reason we have seen 400 bad request is large size of the cookies which contribute to the header size.
        # We should keep reducing the size of what headers are being sent meanwhile we increase this size to mitigate the long header issue.
        client_header_buffer_size 16k;
        large_client_header_buffers 64 32k;
      nginx.ingress.kubernetes.io/service-upstream: "true"
      nginx.org/websocket-services: dataproxy-service
    creationTimestamp: "2025-12-31T02:01:16Z"
    generation: 1
    labels:
      app.kubernetes.io/managed-by: Helm
    name: controlplane-dataproxy
    namespace: union-cp
    resourceVersion: "1767147225160959009"
    uid: beed73ae-a991-4b8c-b4a7-89ad62a7c7e5
  spec:
    ingressClassName: controlplane
    rules:
    - http:
        paths:
        - backend:
            service:
              name: dataproxy
              port:
                number: 80
          path: /data/*
          pathType: ImplementationSpecific
        - backend:
            service:
              name: dataproxy
              port:
                number: 80
          path: /data
          pathType: Prefix
    tls:
    - hosts:
      - localhost
      - controlplane-nginx-controller.union-cp.svc.cluster.local
      secretName: controlplane-tls-cert
  status:
    loadBalancer:
      ingress:
      - ip: 34.118.225.101
- apiVersion: networking.k8s.io/v1
  kind: Ingress
  metadata:
    annotations:
      meta.helm.sh/release-name: unionai-controlplane
      meta.helm.sh/release-namespace: union-cp
      nginx.ingress.kubernetes.io/app-root: /v2
      nginx.ingress.kubernetes.io/backend-protocol: GRPC
      nginx.ingress.kubernetes.io/force-ssl-redirect: "false"
      nginx.ingress.kubernetes.io/limit-rps: "100"
      nginx.ingress.kubernetes.io/proxy-body-size: 6m
      nginx.ingress.kubernetes.io/proxy-buffer-size: 32k
      nginx.ingress.kubernetes.io/proxy-buffers: 4 32k
      nginx.ingress.kubernetes.io/proxy-cookie-domain: ~^ .$host
      nginx.ingress.kubernetes.io/server-snippet: |
        client_header_timeout 604800;
        client_body_timeout 604800;
        # Increasing the default configuration from
        #        client_header_buffer_size       1k;
        #        large_client_header_buffers     4 8k;
        # to default of 16k and 32k for large buffer sizes. These sizes are chosen as a short term mediation until we can collect data to reason
        # about expected header sizs (PE-1101).
        # Historically, we have seen is with the previous 8k max buffer size , the auth endpoint of /me would throw 400 Bad request and due to this ingress controller
        # threw a 500 as it doesn't expect this status code on auth request expected range :  200 <= authcall.status(i.e status of /me call) <=300
        # Code link for ref : https://github.com/nginx/nginx/blob/e734df6664e70f118ca3140bcef6d4f1750fa8fa/src/http/modules/ngx_http_auth_request_module.c#L170-L179
        # Now the main reason we have seen 400 bad request is large size of the cookies which contribute to the header size.
        # We should keep reducing the size of what headers are being sent meanwhile we increase this size to mitigate the long header issue.
        client_header_buffer_size 16k;
        large_client_header_buffers 64 32k;
      nginx.ingress.kubernetes.io/service-upstream: "true"
    creationTimestamp: "2025-12-31T02:01:18Z"
    generation: 1
    labels:
      app.kubernetes.io/managed-by: Helm
    name: controlplane-grpc
    namespace: union-cp
    resourceVersion: "1767147226555839004"
    uid: ef1bfdd1-41fb-43e2-acc5-2e59dcb86a4f
  spec:
    ingressClassName: controlplane
    rules:
    - http:
        paths:
        - backend:
            service:
              name: flyteadmin
              port:
                number: 81
          path: /grpc.health.v1.Health
          pathType: ImplementationSpecific
        - backend:
            service:
              name: flyteadmin
              port:
                number: 81
          path: /grpc.health.v1.Health/*
          pathType: ImplementationSpecific
        - backend:
            service:
              name: flyteadmin
              port:
                number: 81
          path: /flyteidl.service.AuthMetadataService
          pathType: ImplementationSpecific
        - backend:
            service:
              name: flyteadmin
              port:
                number: 81
          path: /flyteidl.service.AuthMetadataService/*
          pathType: ImplementationSpecific
    tls:
    - hosts:
      - localhost
      - controlplane-nginx-controller.union-cp.svc.cluster.local
      secretName: controlplane-tls-cert
  status:
    loadBalancer:
      ingress:
      - ip: 34.118.225.101
- apiVersion: networking.k8s.io/v1
  kind: Ingress
  metadata:
    annotations:
      meta.helm.sh/release-name: unionai-controlplane
      meta.helm.sh/release-namespace: union-cp
      nginx.ingress.kubernetes.io/app-root: /v2
      nginx.ingress.kubernetes.io/backend-protocol: GRPC
      nginx.ingress.kubernetes.io/force-ssl-redirect: "false"
      nginx.ingress.kubernetes.io/limit-rps: "100"
      nginx.ingress.kubernetes.io/proxy-body-size: 6m
      nginx.ingress.kubernetes.io/proxy-buffer-size: 32k
      nginx.ingress.kubernetes.io/proxy-buffers: 4 32k
      nginx.ingress.kubernetes.io/proxy-cookie-domain: ~^ .$host
      nginx.ingress.kubernetes.io/server-snippet: |
        client_header_timeout 604800;
        client_body_timeout 604800;
        # Increasing the default configuration from
        #        client_header_buffer_size       1k;
        #        large_client_header_buffers     4 8k;
        # to default of 16k and 32k for large buffer sizes. These sizes are chosen as a short term mediation until we can collect data to reason
        # about expected header sizs (PE-1101).
        # Historically, we have seen is with the previous 8k max buffer size , the auth endpoint of /me would throw 400 Bad request and due to this ingress controller
        # threw a 500 as it doesn't expect this status code on auth request expected range :  200 <= authcall.status(i.e status of /me call) <=300
        # Code link for ref : https://github.com/nginx/nginx/blob/e734df6664e70f118ca3140bcef6d4f1750fa8fa/src/http/modules/ngx_http_auth_request_module.c#L170-L179
        # Now the main reason we have seen 400 bad request is large size of the cookies which contribute to the header size.
        # We should keep reducing the size of what headers are being sent meanwhile we increase this size to mitigate the long header issue.
        client_header_buffer_size 16k;
        large_client_header_buffers 64 32k;
      nginx.ingress.kubernetes.io/service-upstream: "true"
    creationTimestamp: "2025-12-31T02:01:18Z"
    generation: 1
    labels:
      app.kubernetes.io/managed-by: Helm
    name: controlplane-grpc-streaming
    namespace: union-cp
    resourceVersion: "1767147226350111011"
    uid: f2d9c773-d1e6-4e0a-a88d-703109b10f96
  spec:
    ingressClassName: controlplane
    rules:
    - http:
        paths:
        - backend:
            service:
              name: flyteadmin
              port:
                number: 81
          path: /flyteidl.service.WatchService/WatchExecutionStatusUpdates
          pathType: ImplementationSpecific
    tls:
    - hosts:
      - localhost
      - controlplane-nginx-controller.union-cp.svc.cluster.local
      secretName: controlplane-tls-cert
  status:
    loadBalancer:
      ingress:
      - ip: 34.118.225.101
- apiVersion: networking.k8s.io/v1
  kind: Ingress
  metadata:
    annotations:
      meta.helm.sh/release-name: unionai-controlplane
      meta.helm.sh/release-namespace: union-cp
      nginx.ingress.kubernetes.io/app-root: /v2
      nginx.ingress.kubernetes.io/force-ssl-redirect: "false"
      nginx.ingress.kubernetes.io/limit-rps: "100"
      nginx.ingress.kubernetes.io/proxy-body-size: 6m
      nginx.ingress.kubernetes.io/proxy-buffer-size: 32k
      nginx.ingress.kubernetes.io/proxy-buffers: 4 32k
      nginx.ingress.kubernetes.io/proxy-cookie-domain: ~^ .$host
      nginx.ingress.kubernetes.io/server-snippet: |
        client_header_timeout 604800;
        client_body_timeout 604800;
        # Increasing the default configuration from
        #        client_header_buffer_size       1k;
        #        large_client_header_buffers     4 8k;
        # to default of 16k and 32k for large buffer sizes. These sizes are chosen as a short term mediation until we can collect data to reason
        # about expected header sizs (PE-1101).
        # Historically, we have seen is with the previous 8k max buffer size , the auth endpoint of /me would throw 400 Bad request and due to this ingress controller
        # threw a 500 as it doesn't expect this status code on auth request expected range :  200 <= authcall.status(i.e status of /me call) <=300
        # Code link for ref : https://github.com/nginx/nginx/blob/e734df6664e70f118ca3140bcef6d4f1750fa8fa/src/http/modules/ngx_http_auth_request_module.c#L170-L179
        # Now the main reason we have seen 400 bad request is large size of the cookies which contribute to the header size.
        # We should keep reducing the size of what headers are being sent meanwhile we increase this size to mitigate the long header issue.
        client_header_buffer_size 16k;
        large_client_header_buffers 64 32k;
      nginx.ingress.kubernetes.io/service-upstream: "true"
      nginx.org/websocket-services: dataproxy-service
    creationTimestamp: "2025-12-31T02:01:17Z"
    generation: 1
    labels:
      app.kubernetes.io/managed-by: Helm
    name: controlplane-protected
    namespace: union-cp
    resourceVersion: "1767147225755263000"
    uid: 54cdb54c-e805-4cb7-a393-c86378243a1a
  spec:
    ingressClassName: controlplane
    rules:
    - http:
        paths:
        - backend:
            service:
              name: flyteadmin
              port:
                number: 80
          path: /api
          pathType: ImplementationSpecific
        - backend:
            service:
              name: flyteadmin
              port:
                number: 80
          path: /api/*
          pathType: ImplementationSpecific
        - backend:
            service:
              name: flyteadmin
              port:
                number: 80
          path: /v1/*
          pathType: ImplementationSpecific
        - backend:
            service:
              name: flyteadmin
              port:
                number: 80
          path: /cloudadmin
          pathType: ImplementationSpecific
        - backend:
            service:
              name: flyteadmin
              port:
                number: 80
          path: /cloudadmin/*
          pathType: ImplementationSpecific
        - backend:
            service:
              name: dataproxy
              port:
                number: 81
          path: /actor
          pathType: ImplementationSpecific
        - backend:
            service:
              name: dataproxy
              port:
                number: 81
          path: /actor/*
          pathType: ImplementationSpecific
        - backend:
            service:
              name: dataproxy
              port:
                number: 81
          path: /agent
          pathType: ImplementationSpecific
        - backend:
            service:
              name: dataproxy
              port:
                number: 81
          path: /agent/*
          pathType: ImplementationSpecific
        - backend:
            service:
              name: dataproxy
              port:
                number: 81
          path: /dataplane
          pathType: ImplementationSpecific
        - backend:
            service:
              name: dataproxy
              port:
                number: 81
          path: /dataplane/*
          pathType: ImplementationSpecific
        - backend:
            service:
              name: dataproxy
              port:
                number: 81
          path: /spark-history-server
          pathType: ImplementationSpecific
        - backend:
            service:
              name: dataproxy
              port:
                number: 81
          path: /spark-history-server/*
          pathType: ImplementationSpecific
        - backend:
            service:
              name: dataproxy
              port:
                number: 81
          path: /api/v1/dataproxy
          pathType: ImplementationSpecific
        - backend:
            service:
              name: dataproxy
              port:
                number: 81
          path: /api/v1/dataproxy/*
          pathType: ImplementationSpecific
        - backend:
            service:
              name: executions
              port:
                number: 81
          path: /app
          pathType: ImplementationSpecific
        - backend:
            service:
              name: executions
              port:
                number: 81
          path: /app/*
          pathType: ImplementationSpecific
        - backend:
            service:
              name: executions
              port:
                number: 81
          path: /apps
          pathType: ImplementationSpecific
        - backend:
            service:
              name: executions
              port:
                number: 81
          path: /apps/*
          pathType: ImplementationSpecific
        - backend:
            service:
              name: cluster
              port:
                number: 81
          path: /cluster
          pathType: ImplementationSpecific
        - backend:
            service:
              name: cluster
              port:
                number: 81
          path: /cluster/*
          pathType: ImplementationSpecific
        - backend:
            service:
              name: cluster
              port:
                number: 81
          path: /clusterpool
          pathType: ImplementationSpecific
        - backend:
            service:
              name: cluster
              port:
                number: 81
          path: /clusterpool/*
          pathType: ImplementationSpecific
        - backend:
            service:
              name: cluster
              port:
                number: 81
          path: /clusterconfig
          pathType: ImplementationSpecific
        - backend:
            service:
              name: cluster
              port:
                number: 81
          path: /clusterconfig/*
          pathType: ImplementationSpecific
        - backend:
            service:
              name: organizations
              port:
                number: 81
          path: /org
          pathType: ImplementationSpecific
        - backend:
            service:
              name: organizations
              port:
                number: 81
          path: /org/*
          pathType: ImplementationSpecific
        - backend:
            service:
              name: cluster
              port:
                number: 81
          path: /managed_cluster
          pathType: ImplementationSpecific
        - backend:
            service:
              name: cluster
              port:
                number: 81
          path: /managed_cluster/*
          pathType: ImplementationSpecific
        - backend:
            service:
              name: authorizer
              port:
                number: 81
          path: /authorizer
          pathType: ImplementationSpecific
        - backend:
            service:
              name: authorizer
              port:
                number: 81
          path: /authorizer/*
          pathType: ImplementationSpecific
        - backend:
            service:
              name: identity
              port:
                number: 81
          path: /oauth_app
          pathType: ImplementationSpecific
        - backend:
            service:
              name: identity
              port:
                number: 81
          path: /oauth_app/*
          pathType: ImplementationSpecific
        - backend:
            service:
              name: identity
              port:
                number: 81
          path: /users
          pathType: ImplementationSpecific
        - backend:
            service:
              name: identity
              port:
                number: 81
          path: /users/*
          pathType: ImplementationSpecific
        - backend:
            service:
              name: identity
              port:
                number: 81
          path: /roles
          pathType: ImplementationSpecific
        - backend:
            service:
              name: identity
              port:
                number: 81
          path: /roles/*
          pathType: ImplementationSpecific
        - backend:
            service:
              name: identity
              port:
                number: 81
          path: /policies
          pathType: ImplementationSpecific
        - backend:
            service:
              name: identity
              port:
                number: 81
          path: /policies/*
          pathType: ImplementationSpecific
        - backend:
            service:
              name: identity
              port:
                number: 81
          path: /identities
          pathType: ImplementationSpecific
        - backend:
            service:
              name: identity
              port:
                number: 81
          path: /identities/*
          pathType: ImplementationSpecific
        - backend:
            service:
              name: execution
              port:
                number: 81
          path: /echo
          pathType: ImplementationSpecific
        - backend:
            service:
              name: execution
              port:
                number: 81
          path: /echo/*
          pathType: ImplementationSpecific
        - backend:
            service:
              name: execution
              port:
                number: 81
          path: /execution
          pathType: ImplementationSpecific
        - backend:
            service:
              name: execution
              port:
                number: 81
          path: /execution/*
          pathType: ImplementationSpecific
        - backend:
            service:
              name: execution
              port:
                number: 81
          path: /workspace_registry
          pathType: ImplementationSpecific
        - backend:
            service:
              name: execution
              port:
                number: 81
          path: /workspace_registry/*
          pathType: ImplementationSpecific
        - backend:
            service:
              name: execution
              port:
                number: 81
          path: /workspace_instance
          pathType: ImplementationSpecific
        - backend:
            service:
              name: execution
              port:
                number: 81
          path: /workspace_instance/*
          pathType: ImplementationSpecific
    tls:
    - hosts:
      - localhost
      - controlplane-nginx-controller.union-cp.svc.cluster.local
      secretName: controlplane-tls-cert
  status:
    loadBalancer:
      ingress:
      - ip: 34.118.225.101
- apiVersion: networking.k8s.io/v1
  kind: Ingress
  metadata:
    annotations:
      meta.helm.sh/release-name: unionai-controlplane
      meta.helm.sh/release-namespace: union-cp
      nginx.ingress.kubernetes.io/app-root: /v2
      nginx.ingress.kubernetes.io/backend-protocol: GRPC
      nginx.ingress.kubernetes.io/force-ssl-redirect: "false"
      nginx.ingress.kubernetes.io/limit-rps: "100"
      nginx.ingress.kubernetes.io/proxy-body-size: 6m
      nginx.ingress.kubernetes.io/proxy-buffer-size: 32k
      nginx.ingress.kubernetes.io/proxy-buffers: 4 32k
      nginx.ingress.kubernetes.io/proxy-cookie-domain: ~^ .$host
      nginx.ingress.kubernetes.io/server-snippet: |
        client_header_timeout 604800;
        client_body_timeout 604800;
        # Increasing the default configuration from
        #        client_header_buffer_size       1k;
        #        large_client_header_buffers     4 8k;
        # to default of 16k and 32k for large buffer sizes. These sizes are chosen as a short term mediation until we can collect data to reason
        # about expected header sizs (PE-1101).
        # Historically, we have seen is with the previous 8k max buffer size , the auth endpoint of /me would throw 400 Bad request and due to this ingress controller
        # threw a 500 as it doesn't expect this status code on auth request expected range :  200 <= authcall.status(i.e status of /me call) <=300
        # Code link for ref : https://github.com/nginx/nginx/blob/e734df6664e70f118ca3140bcef6d4f1750fa8fa/src/http/modules/ngx_http_auth_request_module.c#L170-L179
        # Now the main reason we have seen 400 bad request is large size of the cookies which contribute to the header size.
        # We should keep reducing the size of what headers are being sent meanwhile we increase this size to mitigate the long header issue.
        client_header_buffer_size 16k;
        large_client_header_buffers 64 32k;
      nginx.ingress.kubernetes.io/service-upstream: "true"
    creationTimestamp: "2025-12-31T02:01:17Z"
    generation: 1
    labels:
      app.kubernetes.io/managed-by: Helm
    name: controlplane-protected-grpc
    namespace: union-cp
    resourceVersion: "1767147225957231019"
    uid: 3a6048e1-465d-4762-a8f9-f54a4d34e285
  spec:
    ingressClassName: controlplane
    rules:
    - http:
        paths:
        - backend:
            service:
              name: executions
              port:
                number: 80
          path: /cloudidl.execution.ExecutionService/*
          pathType: ImplementationSpecific
        - backend:
            service:
              name: executions
              port:
                number: 80
          path: /cloudidl.execution.ExecutionService
          pathType: ImplementationSpecific
        - backend:
            service:
              name: cluster
              port:
                number: 80
          path: /cloudidl.cluster.ClusterService/*
          pathType: ImplementationSpecific
        - backend:
            service:
              name: cluster
              port:
                number: 80
          path: /cloudidl.cluster.ClusterService
          pathType: ImplementationSpecific
        - backend:
            service:
              name: identity
              port:
                number: 83
          path: /cloudidl.apikey.APIKeyService/*
          pathType: ImplementationSpecific
        - backend:
            service:
              name: identity
              port:
                number: 83
          path: /cloudidl.apikey.APIKeyService
          pathType: ImplementationSpecific
        - backend:
            service:
              name: identity
              port:
                number: 80
          path: /cloudidl.identity.AppsService/*
          pathType: ImplementationSpecific
        - backend:
            service:
              name: identity
              port:
                number: 80
          path: /cloudidl.identity.AppsService
          pathType: ImplementationSpecific
        - backend:
            service:
              name: organizations
              port:
                number: 80
          path: /cloudidl.org.OrgService/*
          pathType: ImplementationSpecific
        - backend:
            service:
              name: organizations
              port:
                number: 80
          path: /cloudidl.org.OrgService
          pathType: ImplementationSpecific
        - backend:
            service:
              name: cluster
              port:
                number: 80
          path: /cloudidl.cloudaccounts.CloudAccountsService/*
          pathType: ImplementationSpecific
        - backend:
            service:
              name: cluster
              port:
                number: 80
          path: /cloudidl.cloudaccounts.CloudAccountsService
          pathType: ImplementationSpecific
        - backend:
            service:
              name: cluster
              port:
                number: 80
          path: /cloudidl.cluster.ManagedClusterService/*
          pathType: ImplementationSpecific
        - backend:
            service:
              name: cluster
              port:
                number: 80
          path: /cloudidl.cluster.ManagedClusterService
          pathType: ImplementationSpecific
        - backend:
            service:
              name: identity
              port:
                number: 80
          path: /cloudidl.identity.UserService/*
          pathType: ImplementationSpecific
        - backend:
            service:
              name: identity
              port:
                number: 80
          path: /cloudidl.identity.UserService
          pathType: ImplementationSpecific
        - backend:
            service:
              name: identity
              port:
                number: 80
          path: /cloudidl.identity.RoleService/*
          pathType: ImplementationSpecific
        - backend:
            service:
              name: identity
              port:
                number: 80
          path: /cloudidl.identity.RoleService
          pathType: ImplementationSpecific
        - backend:
            service:
              name: identity
              port:
                number: 80
          path: /cloudidl.identity.PolicyService/*
          pathType: ImplementationSpecific
        - backend:
            service:
              name: identity
              port:
                number: 80
          path: /cloudidl.identity.PolicyService
          pathType: ImplementationSpecific
        - backend:
            service:
              name: identity
              port:
                number: 80
          path: /cloudidl.identity.SelfServe/*
          pathType: ImplementationSpecific
        - backend:
            service:
              name: identity
              port:
                number: 80
          path: /cloudidl.identity.SelfServe
          pathType: ImplementationSpecific
        - backend:
            service:
              name: identity
              port:
                number: 80
          path: /cloudidl.identity.IdentityService/*
          pathType: ImplementationSpecific
        - backend:
            service:
              name: identity
              port:
                number: 80
          path: /cloudidl.identity.IdentityService
          pathType: ImplementationSpecific
        - backend:
            service:
              name: cluster
              port:
                number: 80
          path: /cloudidl.clusterpool.ClusterPoolService/*
          pathType: ImplementationSpecific
        - backend:
            service:
              name: cluster
              port:
                number: 80
          path: /cloudidl.clusterpool.ClusterPoolService
          pathType: ImplementationSpecific
        - backend:
            service:
              name: cluster
              port:
                number: 80
          path: /cloudidl.clusterconfig.ClusterConfigService/*
          pathType: ImplementationSpecific
        - backend:
            service:
              name: cluster
              port:
                number: 80
          path: /cloudidl.clusterconfig.ClusterConfigService
          pathType: ImplementationSpecific
        - backend:
            service:
              name: authorizer
              port:
                number: 80
          path: /cloudidl.authorizer.AuthorizerService/*
          pathType: ImplementationSpecific
        - backend:
            service:
              name: authorizer
              port:
                number: 80
          path: /cloudidl.authorizer.AuthorizerService
          pathType: ImplementationSpecific
        - backend:
            service:
              name: datacatalog
              port:
                number: 89
          path: /datacatalog.DataCatalog/*
          pathType: ImplementationSpecific
        - backend:
            service:
              name: datacatalog
              port:
                number: 89
          path: /datacatalog.DataCatalog
          pathType: ImplementationSpecific
        - backend:
            service:
              name: cacheservice
              port:
                number: 89
          path: /flyteidl.cacheservice.CacheService/*
          pathType: ImplementationSpecific
        - backend:
            service:
              name: cacheservice
              port:
                number: 89
          path: /flyteidl.cacheservice.CacheService
          pathType: ImplementationSpecific
        - backend:
            service:
              name: cacheservice
              port:
                number: 89
          path: /flyteidl.cacheservice.v2.CacheService/*
          pathType: ImplementationSpecific
        - backend:
            service:
              name: cacheservice
              port:
                number: 89
          path: /flyteidl.cacheservice.v2.CacheService
          pathType: ImplementationSpecific
        - backend:
            service:
              name: dataproxy
              port:
                number: 80
          path: /cloudidl.actor.ActorEnvironmentService
          pathType: ImplementationSpecific
        - backend:
            service:
              name: dataproxy
              port:
                number: 80
          path: /cloudidl.actor.ActorEnvironmentService/*
          pathType: ImplementationSpecific
        - backend:
            service:
              name: dataproxy
              port:
                number: 80
          path: /cloudidl.agent.AgentService
          pathType: ImplementationSpecific
        - backend:
            service:
              name: dataproxy
              port:
                number: 80
          path: /cloudidl.agent.AgentService/*
          pathType: ImplementationSpecific
        - backend:
            service:
              name: dataproxy
              port:
                number: 80
          path: /cloudidl.secret.SecretService
          pathType: ImplementationSpecific
        - backend:
            service:
              name: dataproxy
              port:
                number: 80
          path: /cloudidl.secret.SecretService/*
          pathType: ImplementationSpecific
        - backend:
            service:
              name: dataproxy
              port:
                number: 80
          path: /flyteidl2.secret.SecretService
          pathType: ImplementationSpecific
        - backend:
            service:
              name: dataproxy
              port:
                number: 80
          path: /flyteidl2.secret.SecretService/*
          pathType: ImplementationSpecific
        - backend:
            service:
              name: dataproxy
              port:
                number: 80
          path: /cloudidl.support.SupportService
          pathType: ImplementationSpecific
        - backend:
            service:
              name: dataproxy
              port:
                number: 80
          path: /cloudidl.clouddataproxy.CloudDataProxyService
          pathType: ImplementationSpecific
        - backend:
            service:
              name: dataproxy
              port:
                number: 80
          path: /cloudidl.clouddataproxy.CloudDataProxyService/*
          pathType: ImplementationSpecific
        - backend:
            service:
              name: dataproxy
              port:
                number: 80
          path: /flyteidl.service.DataProxyService
          pathType: ImplementationSpecific
        - backend:
            service:
              name: dataproxy
              port:
                number: 80
          path: /flyteidl.service.DataProxyService/*
          pathType: ImplementationSpecific
        - backend:
            service:
              name: dataproxy
              port:
                number: 80
          path: /cloudidl.logs.LogsService
          pathType: ImplementationSpecific
        - backend:
            service:
              name: dataproxy
              port:
                number: 80
          path: /cloudidl.logs.LogsService/*
          pathType: ImplementationSpecific
        - backend:
            service:
              name: executions
              port:
                number: 80
          path: /cloudidl.workspace.WorkspaceRegistryService
          pathType: ImplementationSpecific
        - backend:
            service:
              name: executions
              port:
                number: 80
          path: /cloudidl.workspace.WorkspaceRegistryService/*
          pathType: ImplementationSpecific
        - backend:
            service:
              name: executions
              port:
                number: 80
          path: /cloudidl.workspace.WorkspaceInstanceService
          pathType: ImplementationSpecific
        - backend:
            service:
              name: executions
              port:
                number: 80
          path: /cloudidl.workspace.WorkspaceInstanceService/*
          pathType: ImplementationSpecific
        - backend:
            service:
              name: executions
              port:
                number: 80
          path: /cloudidl.workflow.RunService
          pathType: ImplementationSpecific
        - backend:
            service:
              name: executions
              port:
                number: 80
          path: /cloudidl.workflow.RunService/*
          pathType: ImplementationSpecific
        - backend:
            service:
              name: executions
              port:
                number: 80
          path: /cloudidl.workflow.InternalRunService
          pathType: ImplementationSpecific
        - backend:
            service:
              name: executions
              port:
                number: 80
          path: /cloudidl.workflow.InternalRunService/*
          pathType: ImplementationSpecific
        - backend:
            service:
              name: executions
              port:
                number: 80
          path: /cloudidl.workflow.TranslatorService
          pathType: ImplementationSpecific
        - backend:
            service:
              name: executions
              port:
                number: 80
          path: /cloudidl.workflow.TranslatorService/*
          pathType: ImplementationSpecific
        - backend:
            service:
              name: executions
              port:
                number: 80
          path: /cloudidl.workflow.TaskService
          pathType: ImplementationSpecific
        - backend:
            service:
              name: executions
              port:
                number: 80
          path: /cloudidl.workflow.TaskService/*
          pathType: ImplementationSpecific
        - backend:
            service:
              name: executions
              port:
                number: 80
          path: /cloudidl.workflow.TriggerService
          pathType: ImplementationSpecific
        - backend:
            service:
              name: executions
              port:
                number: 80
          path: /cloudidl.workflow.TriggerService/*
          pathType: ImplementationSpecific
        - backend:
            service:
              name: queue
              port:
                number: 80
          path: /cloudidl.workflow.QueueService
          pathType: ImplementationSpecific
        - backend:
            service:
              name: queue
              port:
                number: 80
          path: /cloudidl.workflow.QueueService/*
          pathType: ImplementationSpecific
        - backend:
            service:
              name: queue
              port:
                number: 80
          path: /cloudidl.workflow.StateService
          pathType: ImplementationSpecific
        - backend:
            service:
              name: queue
              port:
                number: 80
          path: /cloudidl.workflow.StateService/*
          pathType: ImplementationSpecific
        - backend:
            service:
              name: executions
              port:
                number: 80
          path: /flyteidl2.workflow.RunService
          pathType: ImplementationSpecific
        - backend:
            service:
              name: executions
              port:
                number: 80
          path: /flyteidl2.workflow.RunService/*
          pathType: ImplementationSpecific
        - backend:
            service:
              name: executions
              port:
                number: 80
          path: /flyteidl2.workflow.TranslatorService
          pathType: ImplementationSpecific
        - backend:
            service:
              name: executions
              port:
                number: 80
          path: /flyteidl2.workflow.TranslatorService/*
          pathType: ImplementationSpecific
        - backend:
            service:
              name: executions
              port:
                number: 80
          path: /flyteidl2.task.TaskService
          pathType: ImplementationSpecific
        - backend:
            service:
              name: executions
              port:
                number: 80
          path: /flyteidl2.task.TaskService/*
          pathType: ImplementationSpecific
        - backend:
            service:
              name: queue
              port:
                number: 80
          path: /flyteidl2.workflow.QueueService
          pathType: ImplementationSpecific
        - backend:
            service:
              name: queue
              port:
                number: 80
          path: /flyteidl2.workflow.QueueService/*
          pathType: ImplementationSpecific
        - backend:
            service:
              name: executions
              port:
                number: 80
          path: /flyteidl2.trigger.TriggerService
          pathType: ImplementationSpecific
        - backend:
            service:
              name: executions
              port:
                number: 80
          path: /flyteidl2.trigger.TriggerService/*
          pathType: ImplementationSpecific
        - backend:
            service:
              name: queue
              port:
                number: 80
          path: /flyteidl2.workflow.StateService
          pathType: ImplementationSpecific
        - backend:
            service:
              name: queue
              port:
                number: 80
          path: /flyteidl2.workflow.StateService/*
          pathType: ImplementationSpecific
        - backend:
            service:
              name: dataproxy
              port:
                number: 80
          path: /cloudidl.imagebuilder.ImageService
          pathType: ImplementationSpecific
        - backend:
            service:
              name: dataproxy
              port:
                number: 80
          path: /cloudidl.imagebuilder.ImageService/*
          pathType: ImplementationSpecific
        - backend:
            service:
              name: executions
              port:
                number: 80
          path: /cloudidl.app.AppService/*
          pathType: ImplementationSpecific
        - backend:
            service:
              name: dataproxy
              port:
                number: 80
          path: /cloudidl.app.AppLogsService/*
          pathType: ImplementationSpecific
        - backend:
            service:
              name: dataproxy
              port:
                number: 80
          path: /cloudidl.app.ReplicaService/*
          pathType: ImplementationSpecific
    tls:
    - hosts:
      - localhost
      - controlplane-nginx-controller.union-cp.svc.cluster.local
      secretName: controlplane-tls-cert
  status:
    loadBalancer:
      ingress:
      - ip: 34.118.225.101
- apiVersion: networking.k8s.io/v1
  kind: Ingress
  metadata:
    annotations:
      meta.helm.sh/release-name: unionai-controlplane
      meta.helm.sh/release-namespace: union-cp
      nginx.ingress.kubernetes.io/app-root: /v2
      nginx.ingress.kubernetes.io/backend-protocol: GRPC
      nginx.ingress.kubernetes.io/force-ssl-redirect: "false"
      nginx.ingress.kubernetes.io/limit-rps: "100"
      nginx.ingress.kubernetes.io/proxy-body-size: 6m
      nginx.ingress.kubernetes.io/proxy-buffer-size: 32k
      nginx.ingress.kubernetes.io/proxy-buffers: 4 32k
      nginx.ingress.kubernetes.io/proxy-cookie-domain: ~^ .$host
      nginx.ingress.kubernetes.io/server-snippet: |
        client_header_timeout 604800;
        client_body_timeout 604800;
        # Increasing the default configuration from
        #        client_header_buffer_size       1k;
        #        large_client_header_buffers     4 8k;
        # to default of 16k and 32k for large buffer sizes. These sizes are chosen as a short term mediation until we can collect data to reason
        # about expected header sizs (PE-1101).
        # Historically, we have seen is with the previous 8k max buffer size , the auth endpoint of /me would throw 400 Bad request and due to this ingress controller
        # threw a 500 as it doesn't expect this status code on auth request expected range :  200 <= authcall.status(i.e status of /me call) <=300
        # Code link for ref : https://github.com/nginx/nginx/blob/e734df6664e70f118ca3140bcef6d4f1750fa8fa/src/http/modules/ngx_http_auth_request_module.c#L170-L179
        # Now the main reason we have seen 400 bad request is large size of the cookies which contribute to the header size.
        # We should keep reducing the size of what headers are being sent meanwhile we increase this size to mitigate the long header issue.
        client_header_buffer_size 16k;
        large_client_header_buffers 64 32k;
      nginx.ingress.kubernetes.io/service-upstream: "true"
    creationTimestamp: "2025-12-31T02:01:17Z"
    generation: 1
    labels:
      app.kubernetes.io/managed-by: Helm
    name: controlplane-protected-grpc-streaming
    namespace: union-cp
    resourceVersion: "1767147226149727024"
    uid: 2bb4bb0b-5ff5-44bd-90d9-e5caafa5fe97
  spec:
    ingressClassName: controlplane
    rules:
    - http:
        paths:
        - backend:
            service:
              name: flyteadmin
              port:
                number: 81
          path: /flyteidl.service.AdminService
          pathType: ImplementationSpecific
        - backend:
            service:
              name: flyteadmin
              port:
                number: 81
          path: /flyteidl.service.AdminService/*
          pathType: ImplementationSpecific
        - backend:
            service:
              name: flyteadmin
              port:
                number: 81
          path: /flyteidl.service.WatchService
          pathType: ImplementationSpecific
        - backend:
            service:
              name: flyteadmin
              port:
                number: 81
          path: /flyteidl.service.WatchService/*
          pathType: ImplementationSpecific
        - backend:
            service:
              name: flyteadmin
              port:
                number: 81
          path: /cloudidl.cloudadmin.CloudAdminService
          pathType: ImplementationSpecific
        - backend:
            service:
              name: flyteadmin
              port:
                number: 81
          path: /cloudidl.cloudadmin.CloudAdminService/*
          pathType: ImplementationSpecific
        - backend:
            service:
              name: flyteadmin
              port:
                number: 81
          path: /flyteidl.service.IdentityService
          pathType: ImplementationSpecific
        - backend:
            service:
              name: flyteadmin
              port:
                number: 81
          path: /flyteidl.service.IdentityService/*
          pathType: ImplementationSpecific
        - backend:
            service:
              name: executions
              port:
                number: 80
          path: /cloudidl.echo.EchoService/*
          pathType: ImplementationSpecific
        - backend:
            service:
              name: executions
              port:
                number: 80
          path: /cloudidl.echo.EchoService
          pathType: ImplementationSpecific
        - backend:
            service:
              name: flyteadmin
              port:
                number: 81
          path: /flyteidl.service.SignalService
          pathType: ImplementationSpecific
        - backend:
            service:
              name: flyteadmin
              port:
                number: 81
          path: /flyteidl.service.SignalService/*
          pathType: ImplementationSpecific
        - backend:
            service:
              name: dataproxy
              port:
                number: 80
          path: /cloudidl.actor.ActorEnvironmentService/Stream*
          pathType: ImplementationSpecific
        - backend:
            service:
              name: executions
              port:
                number: 80
          path: /cloudidl.execution.ExecutionService/GetExecutionOperation
          pathType: ImplementationSpecific
        - backend:
            service:
              name: executions
              port:
                number: 80
          path: /cloudidl.workflow.RunLogsService/TailLogs
          pathType: ImplementationSpecific
        - backend:
            service:
              name: executions
              port:
                number: 80
          path: /cloudidl.workflow.RunService/Watch*
          pathType: ImplementationSpecific
        - backend:
            service:
              name: executions
              port:
                number: 80
          path: /cloudidl.workflow.InternalRunService/Record*
          pathType: ImplementationSpecific
        - backend:
            service:
              name: executions
              port:
                number: 80
          path: /cloudidl.workflow.InternalRunService/Update*
          pathType: ImplementationSpecific
        - backend:
            service:
              name: executions
              port:
                number: 80
          path: /cloudidl.workflow.TaskService/Watch*
          pathType: ImplementationSpecific
        - backend:
            service:
              name: queue
              port:
                number: 80
          path: /cloudidl.workflow.LeaseService/Heartbeat
          pathType: ImplementationSpecific
        - backend:
            service:
              name: queue
              port:
                number: 80
          path: /cloudidl.workflow.QueueService/Heartbeat
          pathType: ImplementationSpecific
        - backend:
            service:
              name: queue
              port:
                number: 80
          path: /cloudidl.workflow.StateService/Watch*
          pathType: ImplementationSpecific
        - backend:
            service:
              name: queue
              port:
                number: 80
          path: /cloudidl.workflow.QueueService/StreamLeases
          pathType: ImplementationSpecific
        - backend:
            service:
              name: queue
              port:
                number: 80
          path: /cloudidl.workflow.LeaseService/StreamLeases
          pathType: ImplementationSpecific
        - backend:
            service:
              name: executions
              port:
                number: 80
          path: /flyteidl2.workflow.RunLogsService/TailLogs
          pathType: ImplementationSpecific
        - backend:
            service:
              name: executions
              port:
                number: 80
          path: /flyteidl2.workflow.RunService/Watch*
          pathType: ImplementationSpecific
        - backend:
            service:
              name: executions
              port:
                number: 80
          path: /flyteidl2.task.TaskService/Watch*
          pathType: ImplementationSpecific
        - backend:
            service:
              name: queue
              port:
                number: 80
          path: /flyteidl2.workflow.QueueService/Heartbeat
          pathType: ImplementationSpecific
        - backend:
            service:
              name: queue
              port:
                number: 80
          path: /flyteidl2.workflow.StateService/Watch*
          pathType: ImplementationSpecific
        - backend:
            service:
              name: queue
              port:
                number: 80
          path: /flyteidl2.workflow.QueueService/StreamLeases
          pathType: ImplementationSpecific
        - backend:
            service:
              name: dataproxy
              port:
                number: 80
          path: /cloudidl.logs.LogsService/TailTaskExecutionLogs
          pathType: ImplementationSpecific
        - backend:
            service:
              name: executions
              port:
                number: 80
          path: /cloudidl.workspace.WorkspaceInstanceService/WatchWorkspaceInstances
          pathType: ImplementationSpecific
        - backend:
            service:
              name: executions
              port:
                number: 80
          path: /cloudidl.app.AppService/Watch
          pathType: ImplementationSpecific
        - backend:
            service:
              name: executions
              port:
                number: 80
          path: /cloudidl.app.AppService/Lease
          pathType: ImplementationSpecific
        - backend:
            service:
              name: dataproxy
              port:
                number: 80
          path: /cloudidl.app.AppLogsService/TailLogs
          pathType: ImplementationSpecific
        - backend:
            service:
              name: dataproxy
              port:
                number: 80
          path: /cloudidl.app.ReplicaService/WatchReplicas
          pathType: ImplementationSpecific
    tls:
    - hosts:
      - localhost
      - controlplane-nginx-controller.union-cp.svc.cluster.local
      secretName: controlplane-tls-cert
  status:
    loadBalancer:
      ingress:
      - ip: 34.118.225.101
- apiVersion: networking.k8s.io/v1
  kind: Ingress
  metadata:
    annotations:
      meta.helm.sh/release-name: unionai-controlplane
      meta.helm.sh/release-namespace: union-cp
      nginx.ingress.kubernetes.io/app-root: /v2
      nginx.ingress.kubernetes.io/force-ssl-redirect: "false"
      nginx.ingress.kubernetes.io/limit-rps: "100"
      nginx.ingress.kubernetes.io/proxy-body-size: 6m
      nginx.ingress.kubernetes.io/proxy-buffer-size: 32k
      nginx.ingress.kubernetes.io/proxy-buffers: 4 32k
      nginx.ingress.kubernetes.io/proxy-cookie-domain: ~^ .$host
      nginx.ingress.kubernetes.io/server-snippet: |
        client_header_timeout 604800;
        client_body_timeout 604800;
        # Increasing the default configuration from
        #        client_header_buffer_size       1k;
        #        large_client_header_buffers     4 8k;
        # to default of 16k and 32k for large buffer sizes. These sizes are chosen as a short term mediation until we can collect data to reason
        # about expected header sizs (PE-1101).
        # Historically, we have seen is with the previous 8k max buffer size , the auth endpoint of /me would throw 400 Bad request and due to this ingress controller
        # threw a 500 as it doesn't expect this status code on auth request expected range :  200 <= authcall.status(i.e status of /me call) <=300
        # Code link for ref : https://github.com/nginx/nginx/blob/e734df6664e70f118ca3140bcef6d4f1750fa8fa/src/http/modules/ngx_http_auth_request_module.c#L170-L179
        # Now the main reason we have seen 400 bad request is large size of the cookies which contribute to the header size.
        # We should keep reducing the size of what headers are being sent meanwhile we increase this size to mitigate the long header issue.
        client_header_buffer_size 16k;
        large_client_header_buffers 64 32k;
      nginx.ingress.kubernetes.io/service-upstream: "true"
      nginx.ingress.kubernetes.io/use-regex: "true"
      nginx.org/websocket-services: dataproxy-service
    creationTimestamp: "2025-12-31T02:01:17Z"
    generation: 1
    labels:
      app.kubernetes.io/managed-by: Helm
    name: controlplane-usage
    namespace: union-cp
    resourceVersion: "1767147226751407005"
    uid: f6810bcc-27a5-467c-991c-0d3fc91ad4f8
  spec:
    ingressClassName: controlplane
    rules:
    - http:
        paths:
        - backend:
            service:
              name: usage
              port:
                number: 81
          path: /usage/api/v1(/(?!custom_measures_names|measure_group|measure_groups|billable_measures|billing_info|report_billable_usage|customer_credits|checkout_session).*|$)
          pathType: ImplementationSpecific
    tls:
    - hosts:
      - localhost
      - controlplane-nginx-controller.union-cp.svc.cluster.local
      secretName: controlplane-tls-cert
  status:
    loadBalancer:
      ingress:
      - ip: 34.118.225.101
- apiVersion: networking.k8s.io/v1
  kind: Ingress
  metadata:
    annotations:
      meta.helm.sh/release-name: unionai-controlplane
      meta.helm.sh/release-namespace: union-cp
      nginx.ingress.kubernetes.io/app-root: /v2
      nginx.ingress.kubernetes.io/backend-protocol: GRPC
      nginx.ingress.kubernetes.io/force-ssl-redirect: "false"
      nginx.ingress.kubernetes.io/limit-rps: "100"
      nginx.ingress.kubernetes.io/proxy-body-size: 6m
      nginx.ingress.kubernetes.io/proxy-buffer-size: 32k
      nginx.ingress.kubernetes.io/proxy-buffers: 4 32k
      nginx.ingress.kubernetes.io/proxy-cookie-domain: ~^ .$host
      nginx.ingress.kubernetes.io/server-snippet: |
        client_header_timeout 604800;
        client_body_timeout 604800;
        # Increasing the default configuration from
        #        client_header_buffer_size       1k;
        #        large_client_header_buffers     4 8k;
        # to default of 16k and 32k for large buffer sizes. These sizes are chosen as a short term mediation until we can collect data to reason
        # about expected header sizs (PE-1101).
        # Historically, we have seen is with the previous 8k max buffer size , the auth endpoint of /me would throw 400 Bad request and due to this ingress controller
        # threw a 500 as it doesn't expect this status code on auth request expected range :  200 <= authcall.status(i.e status of /me call) <=300
        # Code link for ref : https://github.com/nginx/nginx/blob/e734df6664e70f118ca3140bcef6d4f1750fa8fa/src/http/modules/ngx_http_auth_request_module.c#L170-L179
        # Now the main reason we have seen 400 bad request is large size of the cookies which contribute to the header size.
        # We should keep reducing the size of what headers are being sent meanwhile we increase this size to mitigate the long header issue.
        client_header_buffer_size 16k;
        large_client_header_buffers 64 32k;
      nginx.ingress.kubernetes.io/service-upstream: "true"
      nginx.ingress.kubernetes.io/use-regex: "true"
    creationTimestamp: "2025-12-31T02:01:16Z"
    generation: 1
    labels:
      app.kubernetes.io/managed-by: Helm
    name: controlplane-usage-grpc
    namespace: union-cp
    resourceVersion: "1767147224955919015"
    uid: a0dd692c-516c-4a39-9c9c-9f01a0740e10
  spec:
    ingressClassName: controlplane
    rules:
    - http:
        paths:
        - backend:
            service:
              name: usage
              port:
                number: 80
          path: /cloudidl.usage.UsageService(/(?!GetCustomMeasuresNames|GetMeasureGroup|GetMeasureGroups|GetBillableMeasures|GetBillingInfo|ReportBillableUsage|ReportServerlessBillableUsage|CreateCustomer|AttachBillingPlanToCustomer|GetCustomerCredits|EnqueueMetronomeRequest|EnqueueStripeRequest|GetOrgCheckoutSession).*|$)
          pathType: ImplementationSpecific
    tls:
    - hosts:
      - localhost
      - controlplane-nginx-controller.union-cp.svc.cluster.local
      secretName: controlplane-tls-cert
  status:
    loadBalancer:
      ingress:
      - ip: 34.118.225.101
kind: List
metadata:
  resourceVersion: ""
